# ORDER_LIST Pipeline - Technical Architecture Documentation

**Version**: 2.1  
**Date**: July 11, 2025  
**Status**: ğŸŸ¢ Production Ready with SharePoint Integration  
**Owner**: Data Engineering Team

## ğŸ“ Architecture Overview

The ORDER_LIST pipeline implements a high-performance Extract-Transform-Load (ETL) architecture optimized for processing large-scale customer order data from multiple Excel files into a unified production database.

### ğŸ¯ Design Principles
- **Performance First**: Optimized for 100K+ records in under 6 minutes
- **Zero Downtime**: Atomic operations with staging/production swaps
- **Fault Tolerance**: Comprehensive error handling and rollback capabilities
- **Scalability**: Designed to handle growing data volumes
- **Maintainability**: Modular components with clear separation of concerns

---

## ğŸ—ï¸ High-Level Architecture

```mermaid
graph TB
    subgraph "â˜ï¸ AZURE CLOUD"
        subgraph "ğŸ“¦ Blob Storage"
            A[ğŸ“„ Customer XLSX Files<br/>~41 files, 100K+ records]
            B[ğŸ“ CSV Staging<br/>Temporary upload area]
        end
        
        subgraph "ğŸ” Authentication"
            C[ğŸ« Service Principal<br/>Client Credentials Flow]
            C2[ğŸ—„ï¸ Database Token Cache<br/>MSAL cache in SQL Server]
        end
        
        subgraph "ğŸ“¡ SharePoint Integration"
            SP[ğŸ“‚ SharePoint Discovery<br/>order_list_blob.py]
        end
    end
    
    subgraph "ğŸ–¥ï¸ PROCESSING ENVIRONMENT"
        subgraph "ğŸ Python Runtime"
            D[âš¡ order_list_extract.py<br/>Azure SDK + Pandas]
            E[ğŸ”„ order_list_transform.py<br/>SQL Generation + DDL]
            F[ğŸ“‹ order_list_pipeline.py<br/>Orchestration Controller]
            G[ğŸ“¤ order_list_blob.py<br/>SharePoint â†’ Blob]
        end
        
        subgraph "ğŸ“Š Utilities Layer"
            H[ğŸ—„ï¸ db_helper.py<br/>Database Connections]
            I[ğŸ“ schema_helper.py<br/>DDL Management]
            J[ğŸ“‹ logger_helper.py<br/>Monitoring & Logging]
            K[ğŸ” auth_helper.py<br/>Database-backed MSAL]
        end
    end
    
    subgraph "ğŸ—„ï¸ SQL SERVER DATABASE"
        subgraph "ğŸ“‚ Raw Tables"
            L[ğŸ“„ x_CUSTOMER_ORDER_LIST_RAW<br/>41 dynamic tables]
        end
        
        subgraph "ğŸ”„ Staging Area"  
            M[ğŸ“Š swp_ORDER_LIST<br/>DDL-compliant staging]
        end
        
        subgraph "ğŸ­ Production"
            N[ğŸ“‹ ORDER_LIST<br/>Unified production table]
        end
        
        subgraph "âš™ï¸ Infrastructure"
            O[ğŸ”— External Data Source<br/>Blob SAS integration]
            P[ğŸ“Š BULK INSERT Operations<br/>High-performance loading]
            Q[ğŸ—„ï¸ msal_token_cache<br/>Database-backed auth]
        end
    end
    
    subgraph "ğŸ›ï¸ ORCHESTRATION LAYER"
        R[ğŸ§ª Test Framework<br/>5-phase validation]
        S[ğŸ“Š Monitoring Dashboard<br/>Real-time metrics]
        T[ğŸ® VS Code Tasks<br/>Developer interface]
        U[ğŸ”„ Kestra Workflows<br/>Production orchestration]
    end
    
    %% Enhanced Data Flow
    SP --> A
    C2 --> G
    C --> G
    G --> A
    A --> D
    C --> D
    D --> L
    L --> E
    E --> M
    M --> N
    
    %% Control Flow  
    F --> G
    F --> D
    F --> E
    F --> R
    F --> S
    U --> F
    
    %% Support Services
    G --> H
    G --> K
    D --> H
    D --> I
    D --> J
    E --> H
    E --> I
    E --> J
    
    %% Staging Operations
    M --> O
    M --> P
    L --> P
    
    %% Authentication Flow
    K --> Q
    K --> C2
    
    %% User Interfaces
    T --> F
    T --> G
    R --> F
    
    %% Styling
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style N fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style M fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style F fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style G fill:#fce4ec,stroke:#c2185b,stroke-width:2px
    style K fill:#ffecb3,stroke:#ff8f00,stroke-width:2px
    style U fill:#e1f5fe,stroke:#0277bd,stroke-width:2px
```

---

## ğŸ”„ Data Flow Architecture

### ğŸ“Š Extract Stage Data Flow

```mermaid
sequenceDiagram
    participant BlobStorage as ğŸ“¦ Azure Blob Storage
    participant ExtractScript as âš¡ order_list_extract.py
    participant AzureAuth as ğŸ” Azure Authentication
    participant Database as ğŸ—„ï¸ SQL Server
    participant CSVStaging as ğŸ“ CSV Staging
    
    Note over ExtractScript: Stage 1: Initialization
    ExtractScript->>AzureAuth: Request Service Principal Token
    AzureAuth-->>ExtractScript: Return Access Token
    ExtractScript->>Database: Test Connection & Create External Data Source
    
    Note over ExtractScript: Stage 2: File Discovery
    ExtractScript->>BlobStorage: List XLSX Files (*.xlsx, *.xls)
    BlobStorage-->>ExtractScript: Return File List (45 files)
    
    Note over ExtractScript: Stage 3: File Processing Loop
    loop For Each Customer File
        ExtractScript->>BlobStorage: Download XLSX File
        BlobStorage-->>ExtractScript: Return File Data
        
        Note over ExtractScript: Data Processing
        ExtractScript->>ExtractScript: Read Excel (MASTER sheet)
        ExtractScript->>ExtractScript: Clean Data (remove empty rows)
        ExtractScript->>ExtractScript: Add Metadata (_SOURCE_FILE, _EXTRACTED_AT)
        
        Note over ExtractScript: Database Operations
        ExtractScript->>Database: Generate Dynamic DDL
        ExtractScript->>Database: CREATE TABLE x_CUSTOMER_ORDER_LIST_RAW
        ExtractScript->>CSVStaging: Upload CSV to Blob Storage
        ExtractScript->>Database: BULK INSERT via External Data Source
        
        Database-->>ExtractScript: Return Row Count Confirmation
    end
    
    Note over ExtractScript: Stage 4: Summary Report
    ExtractScript->>ExtractScript: Generate Performance Metrics
```

### ğŸ”§ Transform Stage Data Flow

```mermaid
sequenceDiagram
    participant RawTables as ğŸ“‚ Raw Tables (45)
    participant TransformScript as ğŸ”„ order_list_transform.py
    participant DDLSchema as ğŸ“ DDL Schema File
    participant StagingTable as ğŸ“Š swp_ORDER_LIST
    participant ProductionTable as ğŸ­ ORDER_LIST
    participant Database as ğŸ—„ï¸ SQL Server
    
    Note over TransformScript: Stage 1: Schema Preparation
    TransformScript->>DDLSchema: Load Production Schema Definition
    DDLSchema-->>TransformScript: Return Column Types & Structure
    TransformScript->>Database: DROP TABLE IF EXISTS swp_ORDER_LIST
    TransformScript->>Database: CREATE TABLE swp_ORDER_LIST (DDL Schema)
    
    Note over TransformScript: Stage 2: Data Consolidation
    loop For Each Customer (45 customers)
        TransformScript->>Database: Generate Server-Side INSERT Statement
        Note over Database: Server-Side Processing
        Database->>RawTables: SELECT with Data Cleaning
        Database->>Database: Apply Type Conversions & Precision Fixes
        Database->>StagingTable: INSERT Cleaned Records
        Database-->>TransformScript: Return Processed Row Count
    end
    
    Note over TransformScript: Stage 3: Quality Validation
    TransformScript->>StagingTable: Validate Schema Compliance
    TransformScript->>StagingTable: Count Records & Check Data Types
    StagingTable-->>TransformScript: Return Validation Results
    
    Note over TransformScript: Stage 4: Atomic Swap
    TransformScript->>Database: BEGIN TRANSACTION
    TransformScript->>Database: RENAME ORDER_LIST to ORDER_LIST_OLD
    TransformScript->>Database: RENAME swp_ORDER_LIST to ORDER_LIST
    TransformScript->>Database: DROP TABLE ORDER_LIST_OLD
    TransformScript->>Database: COMMIT TRANSACTION
    
    Database-->>TransformScript: Confirm Zero-Downtime Swap Complete
```

---

## ğŸ›ï¸ Component Architecture

### ğŸ“¦ Module Dependencies

```mermaid
graph TD
    subgraph "ğŸ¯ PIPELINE ORCHESTRATION"
        A[ğŸ“‹ order_list_pipeline.py<br/>Main Controller]
    end
    
    subgraph "ğŸ”„ CORE PROCESSING MODULES"
        B[âš¡ order_list_extract.py<br/>Blob â†’ Raw Tables]
        C[ğŸ”§ order_list_transform.py<br/>Raw â†’ Staging â†’ Production]
    end
    
    subgraph "ğŸ› ï¸ UTILITY LAYER"
        D[ğŸ—„ï¸ db_helper.py<br/>Database Connections]
        E[ğŸ“ schema_helper.py<br/>DDL & Schema Management]
        F[ğŸ“‹ logger_helper.py<br/>Logging & Monitoring]
        G[ğŸ”„ precision_transformer.py<br/>Numeric Type Handling]
        H[ğŸ“Š schema_aware_staging_helper.py<br/>Staging Operations]
    end
    
    subgraph "ğŸ§ª TESTING FRAMEWORK"
        I[ğŸ“Š test_order_list_complete_pipeline.py<br/>5-Phase Validation]
        J[ğŸ” Debug Scripts<br/>Component Testing]
    end
    
    subgraph "ğŸ® USER INTERFACES"
        K[ğŸ¯ VS Code Tasks<br/>Developer Interface]
        L[ğŸ“‹ Command Line<br/>Production Interface]
    end
    
    subgraph "ğŸ“š EXTERNAL DEPENDENCIES"
        M[ğŸ pandas<br/>Excel Processing]
        N[â˜ï¸ azure-storage-blob<br/>Blob Operations] 
        O[ğŸ” azure-identity<br/>Authentication]
        P[ğŸ—„ï¸ pyodbc<br/>Database Connectivity]
    end
    
    %% Dependencies
    A --> B
    A --> C
    A --> I
    
    B --> D
    B --> E
    B --> F
    B --> M
    B --> N
    B --> O
    B --> P
    
    C --> D
    C --> E
    C --> F
    C --> G
    C --> H
    C --> P
    
    I --> A
    I --> D
    I --> F
    
    K --> A
    L --> A
    
    %% Styling
    style A fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style B fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style C fill:#fff3e0,stroke:#f57c00,stroke-width:2px
    style I fill:#fce4ec,stroke:#c2185b,stroke-width:2px
```

### ğŸ”§ Configuration Management

```mermaid
graph LR
    subgraph "âš™ï¸ CONFIGURATION SOURCES"
        A[ğŸ” Environment Variables<br/>Azure Credentials]
        B[ğŸ“‹ config.yaml<br/>Database Connections]
        C[ğŸ“ DDL Files<br/>Schema Definitions]
        D[ğŸ’¾ Hardcoded Constants<br/>Blob Storage Config]
    end
    
    subgraph "ğŸ“Š CONFIGURATION CONSUMERS"
        E[âš¡ Extract Module<br/>Azure Auth + DB Config]
        F[ğŸ”§ Transform Module<br/>DB Config + DDL Schema]
        G[ğŸ› ï¸ Utility Modules<br/>DB Connections]
        H[ğŸ§ª Test Framework<br/>All Configurations]
    end
    
    A --> E
    B --> E
    B --> F
    B --> G
    B --> H
    C --> F
    D --> E
    
    style A fill:#ffebee,stroke:#d32f2f,stroke-width:2px
    style B fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style C fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style D fill:#fff3e0,stroke:#f57c00,stroke-width:2px
```

---

## ğŸ—„ï¸ Database Schema Architecture

### ğŸ“Š Table Relationships

```mermaid
erDiagram
    ORDER_LIST {
        int ORDER_ID PK
        varchar AAG_ORDER_NUMBER
        varchar CUSTOMER
        varchar STYLE_CODE
        decimal ORDER_QTY
        date DUE_DATE
        varchar COUNTRY_OF_ORIGIN
        varchar FACTORY
        varchar PARTNER_PO
        datetime _EXTRACTED_AT
        varchar _SOURCE_FILE
        varchar _SOURCE_TABLE
    }
    
    x_CUSTOMER_ORDER_LIST_RAW {
        varchar AAG_ORDER_NUMBER
        varchar CUSTOMER
        varchar STYLE_CODE
        varchar ORDER_QTY "String - not typed"
        varchar DUE_DATE "String - not typed"
        varchar COUNTRY_OF_ORIGIN
        varchar FACTORY
        varchar PARTNER_PO
        datetime _EXTRACTED_AT
        varchar _SOURCE_FILE
    }
    
    swp_ORDER_LIST {
        int ORDER_ID PK
        varchar AAG_ORDER_NUMBER
        varchar CUSTOMER
        varchar STYLE_CODE
        decimal ORDER_QTY
        date DUE_DATE
        varchar COUNTRY_OF_ORIGIN
        varchar FACTORY
        varchar PARTNER_PO
        datetime _EXTRACTED_AT
        varchar _SOURCE_FILE
        varchar _SOURCE_TABLE
    }
    
    %% Relationships
    x_CUSTOMER_ORDER_LIST_RAW ||--o{ swp_ORDER_LIST : transforms
    swp_ORDER_LIST ||--|| ORDER_LIST : atomic_swap
```

### ğŸ”„ Schema Evolution Process

```mermaid
flowchart TD
    A[ğŸ“„ Excel Files<br/>Variable Schemas] --> B[ğŸ” Dynamic Schema Detection]
    B --> C[ğŸ“ Raw Table Creation<br/>VARCHAR for all columns]
    C --> D[ğŸ“‹ DDL Schema Loading<br/>Production column types]
    D --> E[ğŸ”„ Type Conversion<br/>Server-side CAST operations]
    E --> F[âœ… Schema Validation<br/>Type compliance check]
    F --> G[ğŸ­ Production Table<br/>Typed & validated]
    
    subgraph "ğŸ›¡ï¸ DATA QUALITY GATES"
        H[ğŸ§® Numeric Precision Validation]
        I[ğŸ“… Date Format Standardization]
        J[ğŸ”¤ String Length Compliance]
        K[âŒ NULL Value Handling]
    end
    
    E --> H
    E --> I
    E --> J
    E --> K
    
    H --> F
    I --> F
    J --> F
    K --> F
    
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style G fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style F fill:#fff3e0,stroke:#f57c00,stroke-width:2px
```

---

## âš¡ Performance Architecture

### ğŸš€ Optimization Strategies

```mermaid
mindmap
  root((âš¡ Performance<br/>Optimization))
    ğŸ”„ Extract Stage
      â˜ï¸ Azure SDK
        Lazy Blob Client Init
        Connection Pooling
        Parallel Downloads
      ğŸ“Š Data Processing
        Pandas Vectorization
        Memory-Efficient Streaming
        Bulk Operations
      ğŸ—„ï¸ Database Loading
        BULK INSERT via SAS
        External Data Sources
        Minimal Logging
    
    ğŸ”§ Transform Stage
      ğŸ–¥ï¸ Server-Side Processing
        SQL Server Optimization
        Reduced Python Overhead
        Native Type Conversion
      ğŸ“ DDL Schema
        Pre-defined Types
        No Dynamic Discovery
        Optimized Column Order
      ğŸ”„ Staging Strategy
        Atomic Swaps
        Zero Downtime
        Rollback Capability
    
    ğŸ›ï¸ Orchestration
      ğŸ Direct Imports
        No Subprocess Overhead
        Shared Memory Space
        Reduced Process Creation
      ğŸ“Š Monitoring
        Real-time Metrics
        Progress Tracking
        Error Detection
```

### ğŸ“Š Performance Benchmarks

| Component | Metric | Target | Achieved | Optimization |
|-----------|--------|--------|----------|--------------|
| **Extract** | Throughput | 300 rec/sec | 478 rec/sec | Azure SDK + BULK INSERT |
| **Transform** | Throughput | 500 rec/sec | 849 rec/sec | Server-side processing |
| **Overall** | Total Time | < 10 min | 5.6 min | Direct imports + staging |
| **Memory** | Peak Usage | < 2GB | ~1.2GB | Streaming + chunking |
| **CPU** | Utilization | < 80% | ~60% | Async operations |
| **Network** | Bandwidth | Minimal | Optimized | SAS + compression |

---

## ğŸ›¡ï¸ Security Architecture

### ğŸ” Authentication & Authorization

```mermaid
sequenceDiagram
    participant Pipeline as ğŸ¯ Pipeline Process
    participant AzureAD as ğŸ” Azure Active Directory
    participant BlobStorage as ğŸ“¦ Blob Storage
    participant Database as ğŸ—„ï¸ SQL Server
    participant SAS as ğŸ« SAS Token Service
    
    Note over Pipeline: Application Startup
    Pipeline->>AzureAD: Service Principal Authentication
    Note over AzureAD: Client Credentials Flow
    AzureAD-->>Pipeline: Access Token (1 hour TTL)
    
    Note over Pipeline: Blob Operations
    Pipeline->>BlobStorage: Access with Bearer Token
    BlobStorage->>AzureAD: Validate Token
    AzureAD-->>BlobStorage: Token Valid
    BlobStorage-->>Pipeline: File Access Granted
    
    Note over Pipeline: Database Operations  
    Pipeline->>Database: Windows Authentication
    Database->>Database: Validate Service Account
    Database-->>Pipeline: Connection Established
    
    Note over Pipeline: CSV Upload Operations
    Pipeline->>SAS: Generate SAS Token (2 hour TTL)
    SAS-->>Pipeline: Temporary Upload Token
    Pipeline->>BlobStorage: Upload CSV with SAS
    BlobStorage-->>Pipeline: Upload Complete
```

### ğŸ›¡ï¸ Security Controls

| Layer | Control | Implementation | Purpose |
|-------|---------|----------------|---------|
| **Authentication** | Service Principal | Client ID + Secret | Azure resource access |
| **Authorization** | RBAC | Storage Blob Data Contributor | Minimal required permissions |
| **Network** | Private Endpoints | VNet integration | Secure data transmission |
| **Data** | Encryption at Rest | Azure Storage SSE | Data protection |
| **Data** | Encryption in Transit | TLS 1.2+ | Network security |
| **Access** | SAS Tokens | Time-limited access | Temporary upload permissions |
| **Audit** | Logging | Comprehensive logs | Security monitoring |

---

## ğŸ§ª Testing Architecture

### ğŸ“Š Test Framework Structure

```mermaid
graph TD
    subgraph "ğŸ§ª TESTING FRAMEWORK"
        A[ğŸ“‹ Main Test Controller<br/>test_order_list_complete_pipeline.py]
        
        subgraph "ğŸ” TEST PHASES"
            B[1ï¸âƒ£ Data Availability<br/>Database connectivity]
            C[2ï¸âƒ£ Extract Validation<br/>File processing & metrics]
            D[3ï¸âƒ£ Transform Validation<br/>Schema & data quality]
            E[4ï¸âƒ£ Data Integrity<br/>Production validation]
            F[5ï¸âƒ£ Performance Testing<br/>Benchmarking & SLA]
        end
        
        subgraph "ğŸ“Š VALIDATION METHODS"
            G[ğŸ—„ï¸ Database Queries<br/>Record counts & schema]
            H[ğŸ“ˆ Performance Metrics<br/>Throughput & timing]
            I[ğŸ” Data Quality Checks<br/>Null values & types]
            J[ğŸ“‹ Schema Compliance<br/>DDL validation]
        end
        
        subgraph "ğŸ“‹ REPORTING"
            K[âœ… Success Metrics<br/>Pass/fail criteria]
            L[âš ï¸ Warning Analysis<br/>Non-critical issues]
            M[âŒ Error Analysis<br/>Actionable feedback]
            N[ğŸ“Š Performance Report<br/>Benchmarking results]
        end
    end
    
    A --> B
    A --> C  
    A --> D
    A --> E
    A --> F
    
    B --> G
    C --> G
    C --> H
    D --> I
    D --> J
    E --> H
    F --> H
    
    G --> K
    H --> N
    I --> L
    J --> M
    
    style A fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px
    style K fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style M fill:#ffebee,stroke:#d32f2f,stroke-width:2px
```

### ğŸ¯ Test Coverage Matrix

| Test Phase | Coverage Area | Success Criteria | Validation Method |
|------------|---------------|------------------|-------------------|
| **Data Availability** | Infrastructure | Database connectivity | Connection tests |
| **Extract Validation** | File Processing | 45 files processed | Record count validation |
| **Transform Validation** | Data Quality | Schema compliance | Type checking |
| **Data Integrity** | Production Data | 100K+ records | Production queries |
| **Performance Testing** | SLA Compliance | < 6 minutes total | Timing benchmarks |

---

## ğŸ“ Recent Updates (Version 2.1)

### ğŸ”„ Pipeline Enhancements
- **Added SharePoint Integration**: Pipeline now starts with `order_list_blob.py` for automated SharePoint file discovery
- **Enhanced Orchestration**: 4-stage pipeline: SharePoint â†’ Blob â†’ Extract â†’ Transform â†’ Load
- **DDL File Reorganization**: Moved schema definition to standardized location

### ğŸ“ File Structure Changes
- **DDL Location**: `db/ddl/tables/orders/dbo_order_list.sql` (previously `notebooks/db/ddl/updates/create_order_list_complete_fixed.sql`)
- **Updated References**: All pipeline components now reference the new DDL path
- **Pipeline Workflow**: Added `--skip-blob` option for flexible execution

### ğŸ¯ Architecture Improvements
- **Complete End-to-End**: Full SharePoint to database automation
- **Database-backed Authentication**: Enterprise MSAL token storage in SQL Server
- **Flexible Execution**: Support for partial pipeline runs (blob-only, extract-only, transform-only)

---

## ğŸ”„ Deployment Architecture

### ğŸš€ Deployment Pipeline

```mermaid
flowchart TD
    subgraph "ğŸ’» DEVELOPMENT"
        A[ğŸ‘¨â€ğŸ’» Code Development<br/>Feature branches]
        B[ğŸ§ª Local Testing<br/>Limited dataset]
        C[ğŸ“Š Code Review<br/>Pull requests]
    end
    
    subgraph "ğŸ§ª TESTING ENVIRONMENT"
        D[ğŸ”„ Integration Testing<br/>Full test suite]
        E[ğŸ“Š Performance Validation<br/>Production-like data]
        F[âœ… Quality Gates<br/>95%+ success rate]
    end
    
    subgraph "ğŸ­ PRODUCTION"
        G[ğŸš€ Production Deployment<br/>Direct execution]
        H[ğŸ“Š Production Monitoring<br/>Real-time metrics]
        I[ğŸ”„ Operational Support<br/>24/7 monitoring]
    end
    
    A --> B
    B --> C
    C --> D
    D --> E
    E --> F
    F --> G
    G --> H
    H --> I
    
    %% Feedback loops
    I -.-> A
    F -.-> A
    E -.-> A
    
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style G fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style F fill:#fff3e0,stroke:#f57c00,stroke-width:2px
```

### ğŸ“‹ Environment Configuration

| Environment | Purpose | Data Volume | Runtime | Monitoring |
|-------------|---------|-------------|---------|------------|
| **Development** | Feature development | 5 files | ~1 minute | Console logs |
| **Testing** | Integration validation | 45 files | ~6 minutes | Full metrics |
| **Production** | Live operations | 45 files | ~6 minutes | 24/7 monitoring |

---

## ğŸ“Š Monitoring Architecture

### ğŸ›ï¸ Observability Stack

```mermaid
graph TB
    subgraph "ğŸ“Š DATA COLLECTION"
        A[ğŸ“‹ Application Logs<br/>Python logging]
        B[ğŸ—„ï¸ Database Metrics<br/>SQL Server logs]
        C[â˜ï¸ Azure Metrics<br/>Blob storage stats]
        D[âš¡ Performance Counters<br/>System resources]
    end
    
    subgraph "ğŸ”„ PROCESSING LAYER"
        E[ğŸ“Š Log Aggregation<br/>Centralized collection]
        F[ğŸ“ˆ Metrics Processing<br/>Statistical analysis]
        G[ğŸš¨ Alert Processing<br/>Threshold monitoring]
    end
    
    subgraph "ğŸ¯ PRESENTATION LAYER"
        H[ğŸ“‹ Console Dashboard<br/>Real-time output]
        I[ğŸ“Š Performance Reports<br/>Execution summaries]
        J[ğŸš¨ Alert Notifications<br/>Issue alerts]
        K[ğŸ“ˆ Trend Analysis<br/>Historical data]
    end
    
    A --> E
    B --> E
    C --> F
    D --> F
    
    E --> H
    F --> I
    G --> J
    F --> K
    
    style A fill:#e3f2fd,stroke:#1976d2,stroke-width:2px
    style H fill:#e8f5e8,stroke:#388e3c,stroke-width:2px
    style J fill:#ffebee,stroke:#d32f2f,stroke-width:2px
```

### ğŸ“Š Key Performance Indicators (KPIs)

| Category | Metric | Target | Threshold | Action |
|----------|--------|--------|-----------|---------|
| **Throughput** | Records/second | 300+ | < 200 | Performance investigation |
| **Reliability** | Success rate | 100% | < 95% | Error analysis |
| **Availability** | Uptime | 99.9% | < 99% | Infrastructure review |
| **Performance** | Total runtime | < 6 min | > 10 min | Optimization required |
| **Quality** | Data accuracy | 100% | < 99% | Data validation |

---

**ğŸ“‹ Document Control**
- **Created**: July 10, 2025
- **Last Updated**: July 11, 2025
- **Next Review**: August 11, 2025
- **Version**: 2.0
- **Status**: ğŸŸ¢ Production Ready
- **Key Updates**: Added SharePoint integration, database-backed authentication, 41 files processed successfully
