# Power BI Operations - File Organization Strategy

**Date:** July 17, 2025 | **Status:** Ready for Implementation  
**Context:** Post-breakthrough file consolidation and domain organization

---

## ğŸ¯ Current State Analysis

### **Breakthrough Achievement:**
- âœ… **Gen1 Dataflow Refresh Working** via Power Automate SAS URL approach
- âœ… **HTTP 202 Success** - Flow triggering dataflow refresh successfully  
- âœ… **Production Ready** - Can be deployed immediately to fill ORDER_LIST pipeline gap

### **File Organization Challenge:**
- **powerbi folder:** 20+ files mixing production code with test/debug scripts
- **load_order_list folder:** Contains existing `order_list_dataflow_refresh.py` needing replacement
- **Scattered implementations:** Working solutions mixed with experimental code
- **Missing domain structure:** No clear separation between production vs development files

---

## ğŸ“‹ File Organization Plan

### **Phase 1: Immediate Production Files (Next 2 Hours)**

#### **ğŸš€ PRIORITY: Replace ORDER_LIST Dataflow Refresh**

**Current File:**
```
pipelines/scripts/load_order_list/order_list_dataflow_refresh.py
```

**Action:** Replace with SAS URL approach from `test_power_automate_sas.py`
- Convert successful test script to production-ready implementation
- Maintain existing logging and import patterns for Kestra compatibility
- Add comprehensive error handling and retry logic
- Include configuration support for different environments

**Implementation Steps:**
1. Copy working logic from `test_power_automate_sas.py`
2. Enhance with production logging using `logger_helper`
3. Add configuration loading using `db_helper.load_config()`
4. Include error handling and status validation
5. Test with existing Kestra workflow integration

---

### **Phase 2: Domain Organization (Next 24 Hours)**

#### **ğŸ—ï¸ CREATE: PowerBI Domain Structure**

**Target Structure:**
```
pipelines/scripts/powerbi/
â”œâ”€â”€ ğŸ“ core/                        # Production implementations
â”‚   â”œâ”€â”€ powerbi_manager.py          # Enhanced universal manager
â”‚   â”œâ”€â”€ dataflow_refresh_gen1.py    # Gen1 SAS URL operations  
â”‚   â”œâ”€â”€ dataflow_refresh_gen2.py    # Gen2 REST API operations
â”‚   â””â”€â”€ resource_discovery.py       # Workspace/resource listing
â”œâ”€â”€ ğŸ“ operations/                  # Specific operation scripts
â”‚   â”œâ”€â”€ refresh_dataflow.py         # Enhanced existing script
â”‚   â””â”€â”€ batch_operations.py         # Batch processing utilities
â””â”€â”€ ğŸ“ utils/                      # PowerBI-specific utilities
    â”œâ”€â”€ auth_helper.py              # PowerBI authentication utilities
    â””â”€â”€ config_loader.py            # PowerBI configuration management
```

#### **ğŸ”§ CREATE: Auth Domain for Kestra**

**Target Structure:**
```
pipelines/scripts/auth/
â”œâ”€â”€ token_manager.py                # Universal token operations
â”œâ”€â”€ token_refresh.py                # Kestra-compatible refresh workflows
â”œâ”€â”€ credential_validator.py         # Validation and diagnostics
â”œâ”€â”€ service_principal_ops.py        # Service principal management
â””â”€â”€ database_token_storage.py       # Enhanced DB token operations
```

#### **ğŸ§ª ORGANIZE: Test and Debug Files**

**Target Structure:**
```
tests/powerbi/
â”œâ”€â”€ ğŸ“ debug/                       # Debug and diagnostic scripts
â”‚   â”œâ”€â”€ debug_power_automate_auth.py
â”‚   â”œâ”€â”€ test_*.py                   # All test files
â”‚   â””â”€â”€ diagnostic_*.py             # All diagnostic files
â”œâ”€â”€ ğŸ“ archive/                     # Obsolete files for reference
â”‚   â””â”€â”€ [obsolete experimental files]
â””â”€â”€ ğŸ“ integration/                 # Integration tests
    â”œâ”€â”€ test_gen1_dataflow_refresh.py
    â””â”€â”€ test_kestra_integration.py
```

---

### **Phase 3: File Movement Strategy**

#### **ğŸ¯ KEEP & ENHANCE (Priority Production Files)**

**Files to Keep in powerbi/core/:**
1. **`powerbi_manager.py`** â†’ Enhanced as universal manager
   - Current: Basic implementation
   - Enhancement: Add Gen1 SAS URL support, Gen2 REST API, resource discovery
   
2. **`load_tokens.py`** â†’ Move to auth domain as enhanced token CLI
   - Current: PowerBI-specific token loading
   - Enhancement: Universal token management across all Azure services

#### **ğŸ”„ MOVE TO DEBUG (Test/Development Files)**

**Files to Move to tests/powerbi/debug/:**
```
test_power_automate_configured.py   â†’ tests/powerbi/debug/
test_power_automate_simple_check.py â†’ tests/powerbi/debug/
debug_power_automate_auth.py        â†’ tests/powerbi/debug/
test_power_automate_sas.py          â†’ tests/powerbi/debug/ (keep working prototype)
[Additional test_*.py files]         â†’ tests/powerbi/debug/
```

#### **ğŸ—‘ï¸ ARCHIVE (Obsolete Files)**

**Files to Move to tests/powerbi/archive/:**
```
[Experimental OAuth implementations that didn't work]
[Obsolete diagnostic scripts]
[Failed authentication approaches]
```

#### **ğŸ—ï¸ CREATE NEW (Production Enhancements)**

**New Files to Create:**
1. **`pipelines/scripts/powerbi/core/dataflow_refresh_gen1.py`**
   - Production-ready Gen1 dataflow refresh using SAS URL
   - Based on successful `test_power_automate_sas.py` prototype
   - Enhanced with configuration, logging, error handling

2. **`pipelines/scripts/auth/token_manager.py`**
   - Universal token management for all Azure services
   - Kestra-compatible workflows
   - Database integration for credential storage

3. **`pipelines/scripts/auth/service_principal_validator.py`**
   - Validate service principal setup and permissions
   - Diagnostic utilities for authentication troubleshooting

---

## ğŸ”§ Implementation Sequence

### **Step 1: Critical Production Replacement (Immediate)**
```powershell
# 1. Backup existing file
Copy-Item "pipelines/scripts/load_order_list/order_list_dataflow_refresh.py" "pipelines/scripts/load_order_list/order_list_dataflow_refresh.py.backup"

# 2. Create enhanced production version from working prototype
# (Convert test_power_automate_sas.py to production script)

# 3. Test with existing Kestra workflow
# 4. Deploy and validate first production run
```

### **Step 2: Domain Creation (Next 4 Hours)**
```powershell
# 1. Create domain folders
New-Item -Path "pipelines/scripts/powerbi/core" -ItemType Directory -Force
New-Item -Path "pipelines/scripts/powerbi/operations" -ItemType Directory -Force  
New-Item -Path "pipelines/scripts/powerbi/utils" -ItemType Directory -Force
New-Item -Path "pipelines/scripts/auth" -ItemType Directory -Force

# 2. Create test organization folders
New-Item -Path "tests/powerbi/debug" -ItemType Directory -Force
New-Item -Path "tests/powerbi/archive" -ItemType Directory -Force
New-Item -Path "tests/powerbi/integration" -ItemType Directory -Force
```

### **Step 3: File Movement and Enhancement (Next 8 Hours)**
```powershell
# 1. Move debug/test files to appropriate test folders
# 2. Enhance core production files
# 3. Create new auth domain utilities
# 4. Update all import statements
# 5. Test all moved and enhanced files
```

### **Step 4: Integration and Validation (Next 12 Hours)**
```powershell
# 1. Update Kestra workflows with new file paths
# 2. Test ORDER_LIST pipeline with new dataflow refresh
# 3. Validate all production operations
# 4. Update documentation and runbooks
```

---

## ğŸ“Š Before/After Comparison

### **Before: Disorganized State**
```
pipelines/scripts/powerbi/
â”œâ”€â”€ powerbi_manager.py              # Production + many test files mixed
â”œâ”€â”€ test_power_automate_sas.py      # WORKING PROTOTYPE (success!)
â”œâ”€â”€ test_power_automate_*.py        # Multiple test variations
â”œâ”€â”€ debug_power_automate_auth.py    # Debug files
â”œâ”€â”€ load_tokens.py                  # Token management
â””â”€â”€ [15+ other mixed files]

pipelines/scripts/load_order_list/
â””â”€â”€ order_list_dataflow_refresh.py  # NEEDS REPLACEMENT (old approach)
```

### **After: Clean Domain Organization**
```
pipelines/scripts/powerbi/core/
â”œâ”€â”€ powerbi_manager.py              # Enhanced universal manager
â”œâ”€â”€ dataflow_refresh_gen1.py        # NEW: Production Gen1 refresh
â””â”€â”€ dataflow_refresh_gen2.py        # Enhanced Gen2 operations

pipelines/scripts/auth/
â”œâ”€â”€ token_manager.py                # Universal token operations
â”œâ”€â”€ token_refresh.py                # Kestra workflows
â””â”€â”€ service_principal_ops.py        # Service principal management

pipelines/scripts/load_order_list/
â””â”€â”€ order_list_dataflow_refresh.py  # REPLACED: SAS URL approach

tests/powerbi/debug/
â”œâ”€â”€ test_power_automate_sas.py      # Working prototype preserved
â””â”€â”€ [All test and debug files]
```

---

## ğŸ¯ Success Criteria

### **Phase 1 Success (Production Ready):**
- âœ… ORDER_LIST dataflow refresh working with new SAS URL approach
- âœ… Kestra workflow integration maintained and functional
- âœ… Production logging and error handling implemented
- âœ… First successful production run validated

### **Phase 2 Success (Domain Organization):**
- âœ… Clean separation between production and development code
- âœ… PowerBI domain properly structured for future expansion
- âœ… Auth domain created for Kestra-compatible token workflows
- âœ… All test files organized and accessible for debugging

### **Phase 3 Success (Platform Foundation):**
- âœ… Enhanced production scripts supporting both Gen1 and Gen2 operations
- âœ… Universal token management system operational
- âœ… Configuration-driven resource management implemented
- âœ… Documentation updated and team trained on new structure

---

## ğŸš¨ Risk Mitigation

### **Production Continuity:**
- **Backup Strategy:** All existing files backed up before replacement
- **Rollback Plan:** Preserve working `test_power_automate_sas.py` as reference
- **Testing Protocol:** Validate each file movement and enhancement
- **Kestra Integration:** Maintain existing logging and import patterns

### **File Organization Risks:**
- **Import Dependencies:** Update all import statements systematically
- **Path References:** Check all script references and VS Code tasks
- **Configuration Files:** Update any hardcoded file paths
- **Documentation:** Update all references to moved files

---

*This organization strategy transforms our breakthrough achievement into a production-ready, scalable platform while maintaining operational continuity.*
