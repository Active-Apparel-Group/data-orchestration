"""
Breaking Change Scanner
Scans the codebase for hardcoded file paths that need updating during database folder restructure
Part of the breaking change prevention strategy
"""

import os
import re
import json
from typing import Dict, List, Tuple, Any
from pathlib import Path

class BreakingChangeScanner:
    """Scans for hardcoded file paths that will break during restructuring"""
    
    def __init__(self, project_root: str = None):
        """
        Initialize the scanner
        
        Args:
            project_root: Path to project root. If None, auto-detects from this file location
        """
        if project_root is None:
            # Auto-detect project root relative to this file
            current_dir = Path(__file__).parent.parent.parent
            self.project_root = current_dir
        else:
            self.project_root = Path(project_root)
            
        # Define file patterns that will break
        self.breaking_patterns = {
            'utils_config': r'utils[/\\]config\.ya?ml',
            'utils_data_mapping': r'utils[/\\]data_mapping\.ya?ml',
            'utils_master_field_mapping': r'utils[/\\]master_field_mapping\.json',
            'utils_subitems_mapping': r'utils[/\\]subitems_mapping_schema\.json',
            'sql_ddl_paths': r'sql[/\\]ddl[/\\]',
            'docs_mapping_paths': r'docs[/\\]mapping[/\\]',
            'queries_folder': r'queries[/\\]',
            'utils_any_json': r'utils[/\\].*\.json',
            'utils_any_yaml': r'utils[/\\].*\.ya?ml'
        }
        
        # File extensions to scan
        self.scan_extensions = {
            '.py', '.yml', '.yaml', '.md', '.ps1', '.json', '.j2', '.sql'
        }
        
        # Directories to exclude from scanning
        self.exclude_dirs = {
            '__pycache__', '.git', '.vscode', 'node_modules', '.pytest_cache'
        }
        
    def scan_all(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        Scan entire project for breaking file references
        
        Returns:
            Dictionary with pattern names as keys and lists of matches as values
        """
        results = {pattern: [] for pattern in self.breaking_patterns.keys()}
        
        for file_path in self._get_files_to_scan():
            matches = self._scan_file(file_path)
            
            for pattern_name, file_matches in matches.items():
                if file_matches:
                    results[pattern_name].extend(file_matches)
                    
        return results
        
    def scan_critical_utils_references(self) -> Dict[str, List[Dict[str, Any]]]:
        """
        Scan for the most critical utils/ file references that will cause runtime failures
        
        Returns:
            Dictionary with critical pattern matches
        """
        critical_patterns = {
            'utils_config': self.breaking_patterns['utils_config'],
            'utils_data_mapping': self.breaking_patterns['utils_data_mapping'],
            'utils_master_field_mapping': self.breaking_patterns['utils_master_field_mapping'],
            'utils_subitems_mapping': self.breaking_patterns['utils_subitems_mapping']
        }
        
        results = {pattern: [] for pattern in critical_patterns.keys()}
        
        for file_path in self._get_files_to_scan():
            content = self._read_file_safe(file_path)
            if content is None:
                continue
                
            for pattern_name, pattern in critical_patterns.items():
                matches = re.finditer(pattern, content, re.IGNORECASE)
                
                for match in matches:
                    line_num = content[:match.start()].count('\\n') + 1
                    line_content = self._get_line_content(content, line_num)
                    
                    results[pattern_name].append({
                        'file': str(file_path.relative_to(self.project_root)),
                        'line': line_num,
                        'match': match.group(),
                        'line_content': line_content.strip(),
                        'pattern': pattern_name
                    })
                    
        return results
        
    def generate_update_script(self, scan_results: Dict[str, List[Dict[str, Any]]]) -> str:
        """
        Generate a PowerShell script to update file references
        
        Args:
            scan_results: Results from scan_all() or scan_critical_utils_references()
            
        Returns:
            PowerShell script content for updating file references
        """
        script_lines = [
            "# Auto-generated script to update file references for database folder restructure",
            "# Generated by BreakingChangeScanner",
            "",
            "Write-Host 'Starting file reference updates...' -ForegroundColor Green",
            ""
        ]
        
        # Define replacement mappings
        replacements = {
            'utils/config.yaml': 'utils/config.yaml',  # This one stays
            'utils/data_mapping.yaml': 'database/mappings/orders-unified-mapping.yaml',
            'utils/master_field_mapping.json': 'database/mappings/orders-monday-master.json',
            'utils/subitems_mapping_schema.json': 'database/mappings/orders-monday-subitems.json',
            'sql/ddl/': 'database/ddl/',
            'docs/mapping/': 'database/mappings/',
            'queries/': 'database/queries/'
        }
        
        for pattern_name, matches in scan_results.items():
            if not matches:
                continue
                
            script_lines.append(f"# Updating {pattern_name} references ({len(matches)} files)")
            
            for match in matches:
                file_path = match['file']
                old_ref = match['match']
                
                # Find appropriate replacement
                new_ref = old_ref
                for old_pattern, new_pattern in replacements.items():
                    if old_pattern.replace('/', '\\\\') in old_ref or old_pattern.replace('\\\\', '/') in old_ref:
                        new_ref = old_ref.replace(old_pattern.replace('/', '\\\\'), new_pattern.replace('/', '\\\\'))
                        new_ref = new_ref.replace(old_pattern.replace('\\\\', '/'), new_pattern.replace('\\\\', '/'))
                        break
                        
                if new_ref != old_ref:
                    script_lines.append(f"# File: {file_path} (line {match['line']})")
                    script_lines.append(f"(Get-Content '{file_path}') -replace '{re.escape(old_ref)}', '{new_ref}' | Set-Content '{file_path}'")
                    script_lines.append("")
                    
        script_lines.extend([
            "",
            "Write-Host 'File reference updates completed!' -ForegroundColor Green",
            "Write-Host 'Please review changes and test thoroughly before committing.' -ForegroundColor Yellow"
        ])
        
        return "\\n".join(script_lines)
        
    def _get_files_to_scan(self) -> List[Path]:
        """Get list of files to scan for breaking references"""
        files_to_scan = []
        
        for root, dirs, files in os.walk(self.project_root):
            # Remove excluded directories
            dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
            
            for file in files:
                file_path = Path(root) / file
                if file_path.suffix in self.scan_extensions:
                    files_to_scan.append(file_path)
                    
        return files_to_scan
        
    def _scan_file(self, file_path: Path) -> Dict[str, List[Dict[str, Any]]]:
        """Scan a single file for breaking patterns"""
        results = {pattern: [] for pattern in self.breaking_patterns.keys()}
        
        content = self._read_file_safe(file_path)
        if content is None:
            return results
            
        for pattern_name, pattern in self.breaking_patterns.items():
            matches = re.finditer(pattern, content, re.IGNORECASE)
            
            for match in matches:
                line_num = content[:match.start()].count('\\n') + 1
                line_content = self._get_line_content(content, line_num)
                
                results[pattern_name].append({
                    'file': str(file_path.relative_to(self.project_root)),
                    'line': line_num,
                    'match': match.group(),
                    'line_content': line_content.strip(),
                    'pattern': pattern_name
                })
                
        return results
        
    def _read_file_safe(self, file_path: Path) -> str:
        """Safely read file content, handling encoding issues"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except (UnicodeDecodeError, PermissionError):
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    return f.read()
            except Exception:
                return None
                
    def _get_line_content(self, content: str, line_num: int) -> str:
        """Get the content of a specific line from file content"""
        lines = content.split('\\n')
        if 1 <= line_num <= len(lines):
            return lines[line_num - 1]
        return ""
        
    def print_summary(self, scan_results: Dict[str, List[Dict[str, Any]]]):
        """Print a summary of breaking changes found"""
        total_files = len(set(match['file'] for matches in scan_results.values() for match in matches))
        total_references = sum(len(matches) for matches in scan_results.values())
        
        print(f"\\nğŸ” Breaking Change Scanner Results")
        print(f"ğŸ“ Files affected: {total_files}")
        print(f"ğŸ”— Total references: {total_references}")
        print("\\nğŸ“Š Breakdown by pattern:")
        
        for pattern_name, matches in scan_results.items():
            if matches:
                files_count = len(set(match['file'] for match in matches))
                print(f"   {pattern_name}: {len(matches)} references in {files_count} files")
                
        print("\\nğŸš¨ Critical files that will cause runtime failures:")
        critical_patterns = ['utils_config', 'utils_data_mapping', 'utils_master_field_mapping', 'utils_subitems_mapping']
        
        for pattern in critical_patterns:
            matches = scan_results.get(pattern, [])
            if matches:
                print(f"   {pattern}: {len(matches)} references")
                for match in matches[:3]:  # Show first 3 examples
                    print(f"      â€¢ {match['file']}:{match['line']}")
                if len(matches) > 3:
                    print(f"      ... and {len(matches) - 3} more")


if __name__ == "__main__":
    # Test the breaking change scanner
    scanner = BreakingChangeScanner()
    
    print("ğŸ” Scanning for breaking file references...")
    
    # First scan for critical utils references
    critical_results = scanner.scan_critical_utils_references()
    
    print("\\nğŸš¨ Critical Utils References (will cause runtime failures):")
    scanner.print_summary(critical_results)
    
    # Generate update script
    update_script = scanner.generate_update_script(critical_results)
    
    # Save update script
    script_path = scanner.project_root / "tools" / "update_file_references.ps1"
    with open(script_path, 'w', encoding='utf-8') as f:
        f.write(update_script)
        
    print(f"\\nğŸ’¾ Generated update script: {script_path}")
    print("\\nâœ… Breaking change scan completed!")
    print("\\nğŸ“‹ Next steps:")
    print("   1. Review the generated PowerShell script")
    print("   2. Create backup before running updates")
    print("   3. Run the script to update file references")
    print("   4. Test all affected functionality")
