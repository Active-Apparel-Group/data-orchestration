#!/usr/bin/env python3
"""
GENERATED ETL Script: Monday.com Board {{ board_name }} to SQL Server
Board ID: {{ board_id }}
Table: {{ table_name }}
Database: {{ database }}
Generated: {{ generation_timestamp }}

This script was automatically generated by the Dynamic Monday.com Board Template System.
"""

import os, requests, pandas as pd, pyodbc, asyncio, concurrent.futures
from datetime import datetime
import time
import sys
from pathlib import Path

# Repository root discovery (preserved from original)
def find_repo_root():
    """Find the repository root by looking for utils folder"""
    current_path = Path(__file__).resolve()
    while current_path.parent != current_path:  # Not at filesystem root
        utils_path = current_path / "utils"
        if utils_path.exists() and (utils_path / "db_helper.py").exists():
            return current_path
        current_path = current_path.parent
    raise RuntimeError("Could not find repository root with utils folder")

# Add utils to path using repository root method
repo_root = find_repo_root()
sys.path.insert(0, str(repo_root / "utils"))
import db_helper as db

# Load configuration from centralized config
config = db.load_config()

# Configuration - Board-specific settings
BOARD_ID = {{ board_id }}
TABLE_NAME = "{{ table_name }}"
DATABASE_NAME = "{{ database }}"
BOARD_NAME = "{{ board_name }}"

# Monday.com API settings
MONDAY_TOKEN = os.getenv('MONDAY_API_KEY') or config.get('apis', {}).get('monday', {}).get('api_token')
API_VER = "2025-04"
API_URL = config.get('apis', {}).get('monday', {}).get('api_url', "https://api.monday.com/v2")

if not MONDAY_TOKEN or MONDAY_TOKEN == "YOUR_MONDAY_API_TOKEN_HERE":
    raise ValueError("Monday.com API token not configured. Please set MONDAY_API_KEY environment variable or update utils/config.yaml")

HEADERS = {
    "Authorization": f"Bearer {MONDAY_TOKEN}",
    "API-Version": API_VER,
    "Content-Type": "application/json"
}

# Performance settings (configurable)
BATCH_SIZE = {{ batch_size | default(100) }}
MAX_WORKERS = {{ max_workers | default(8) }}
RATE_LIMIT_DELAY = {{ rate_limit_delay | default(0.1) }}

def gql(query_string):
    """Execute GraphQL query against Monday.com API"""
    response = requests.post(
        API_URL,
        headers=HEADERS,
        json={"query": query_string}
    )
    response.raise_for_status()
    return response.json()["data"]

def fetch_board_data_with_pagination():
    """Fetch ALL items from Monday.com board using cursor-based pagination"""
    print(f"üì° Fetching data from Monday.com board {BOARD_ID} ({{ board_name }}) with pagination...")
    
    all_items = []
    cursor = None
    page_num = 1
    board_name = None
    
    while True:
        # Build query with pagination cursor
        cursor_arg = f', cursor: "{cursor}"' if cursor else ''
        
        # GraphQL query for this specific board - using string formatting to avoid Jinja2 conflicts
        query_template = """
        query GetBoardItems {
          boards(ids: BOARD_ID_PLACEHOLDER) {
            name
            items_page(limit: 250CURSOR_PLACEHOLDER) {
              cursor
              items {
                id
                name
                updated_at
                created_at
                group {
                  id
                  title
                }
                column_values {
                  column {
                    title
                    id
                    type
                  }
                  value
                  text
                  ... on DependencyValue { display_value }
                  ... on MirrorValue { display_value }
                  ... on BoardRelationValue { display_value }
                  ... on FormulaValue { display_value }
                  ... on TextValue { text }
                  ... on LongTextValue { text }
                  ... on StatusValue { label }
                  ... on PeopleValue { text }
                  ... on DropdownValue { text }
                  ... on ItemIdValue { item_id }
                  ... on NumbersValue { number }
                }
              }
            }
          }
        }
        """
        
        query = query_template.replace("BOARD_ID_PLACEHOLDER", str(BOARD_ID)).replace("CURSOR_PLACEHOLDER", cursor_arg)
        
        data = gql(query)
        board = data["boards"][0]
        
        # Store board name from first page
        if board_name is None:
            board_name = board["name"]
        
        items_page = board["items_page"]
        items = items_page["items"]
        
        # Add items from this page
        all_items.extend(items)
        
        print(f"   üìÑ Page {page_num}: Fetched {len(items)} items (Total: {len(all_items)})")
        
        # Check if there are more pages
        cursor = items_page.get("cursor")
        if not cursor or len(items) == 0:
            break
            
        page_num += 1
        
        # Add a small delay to respect rate limits
        time.sleep(RATE_LIMIT_DELAY)
    
    print(f"‚úÖ Fetched {len(all_items)} total items from board '{board_name}' across {page_num} pages")
    return all_items, board_name

def truncate_table():
    """PRODUCTION: Truncate the table before full refresh"""
    print("üóëÔ∏è TRUNCATING table for full refresh...")
    
    try:
        # Get current record count
        count_result = db.run_query(f"SELECT COUNT(*) as count FROM dbo.{TABLE_NAME}", DATABASE_NAME)
        old_count = count_result.iloc[0]['count']
        print(f"   üìä Current records in table: {old_count}")
        
        # Truncate the table
        db.execute(f"TRUNCATE TABLE dbo.{TABLE_NAME}", DATABASE_NAME)
        
        # Verify truncation
        verify_result = db.run_query(f"SELECT COUNT(*) as count FROM dbo.{TABLE_NAME}", DATABASE_NAME)
        new_count = verify_result.iloc[0]['count']
        
        print(f"   ‚úÖ Table truncated: {old_count} ‚Üí {new_count} records")
        
    except Exception as e:
        print(f"   ‚ùå Truncate failed: {e}")
        raise

def safe_date_convert(value):
    """Safely convert value to date"""
    if not value or value in ['', 'None', None]:
        return None
    try:
        if isinstance(value, str):
            # Try parsing common date formats
            for fmt in ['%Y-%m-%d', '%m/%d/%Y', '%d/%m/%Y', '%Y-%m-%d %H:%M:%S']:
                try:
                    return datetime.strptime(value, fmt).date()
                except ValueError:
                    continue
        return value
    except:
        return None

def safe_numeric_convert(value):
    """Safely convert value to numeric"""
    if not value or value in ['', 'None', None]:
        return None
    try:
        if isinstance(value, str):
            # Remove common non-numeric characters
            cleaned = value.replace(',', '').replace('$', '').strip()
            return int(float(cleaned))
        return int(value)
    except:
        return None

def extract_value(column_value):
    """Extract the correct value from Monday.com column based on type"""
    cv = column_value
    column_type = cv["column"]["type"]
    column_title = cv["column"]["title"]
    
    # Board-specific custom conversion logic would go here
    {% for column in columns %}
    {% if column.conversion_logic %}
    # Custom logic for {{ column.monday_title }} ({{ column.monday_type }})
    if column_title == "{{ column.monday_title }}":
        return {{ column.conversion_logic }}
    {% endif %}
    {% endfor %}
    
    # Default extraction logic (preserved from reference implementation)
    if column_type == "date":
        if cv.get("text") and cv.get("text").strip():
            return cv["text"]
        elif cv.get("value") and cv.get("value") != "None":
            return cv["value"]
        else:
            return None
    elif column_type == "dropdown" and cv.get("text"):
        return cv["text"]
    elif column_type == "status" and cv.get("label"):
        return cv["label"]
    elif column_type == "numbers" and cv.get("number") is not None:
        return cv["number"]
    elif column_type == "item_id" and cv.get("item_id"):
        return cv["item_id"]
    elif cv.get("display_value") and cv.get("display_value") != "":
        return cv["display_value"]
    elif cv.get("text"):
        return cv["text"]
    elif cv.get("value"):
        return cv["value"]
    
    return None

def process_items(items):
    """Convert Monday.com items to DataFrame"""
    print(f"üîÑ Processing {len(items)} items...")
    
    records = []
    for item in items:
        record = {
            {% for column in columns %}
            {% if not column.is_system_field %}
            "{{ column.sql_column }}": None,  # Will be populated from column_values
            {% endif %}
            {% endfor %}
        }
        
        # System fields (always present)
        record["_item_id"] = item["id"]
        record["_item_name"] = item["name"]
        record["_updated_at"] = item["updated_at"]
        record["_created_at"] = item.get("created_at")
        record["_group_title"] = item["group"]["title"]
        
        # Extract column values using board-specific mapping
        for cv in item["column_values"]:
            column_title = cv["column"]["title"]
            
            {% for column in columns %}
            {% if not column.is_system_field %}
            if column_title == "{{ column.monday_title }}":
                record["{{ column.sql_column }}"] = extract_value(cv)
            {% endif %}
            {% endfor %}
        
        records.append(record)
    
    df = pd.DataFrame(records)
    print(f"‚úÖ Created DataFrame with {len(df)} rows and {len(df.columns)} columns")
    return df

def prepare_for_database(df):
    """Prepare DataFrame for database insert with robust conversions"""
    print("üîß Preparing data for database insert...")
    
    {% for column in columns %}
    {% if column.sql_type == "DATE" %}
    # Date column: {{ column.sql_column }}
    if "{{ column.sql_column }}" in df.columns:
        print(f"   üóìÔ∏è Converting {{ column.sql_column }} to DATE...")
        df["{{ column.sql_column }}"] = df["{{ column.sql_column }}"].apply(safe_date_convert)
    {% elif column.sql_type in ["BIGINT", "INT"] %}
    # Numeric column: {{ column.sql_column }}
    if "{{ column.sql_column }}" in df.columns:
        print(f"   üî¢ Converting {{ column.sql_column }} to {{ column.sql_type }}...")
        df["{{ column.sql_column }}"] = df["{{ column.sql_column }}"].apply(safe_numeric_convert)
    {% elif column.sql_type == "BIT" %}
    # Boolean column: {{ column.sql_column }}
    if "{{ column.sql_column }}" in df.columns:
        print(f"   ‚òëÔ∏è Converting {{ column.sql_column }} to BIT...")
        df["{{ column.sql_column }}"] = df["{{ column.sql_column }}"].apply(
            lambda x: 1 if x and str(x).lower() in ['true', '1', 'yes', 'checked'] else 0
        )
    {% endif %}
    {% endfor %}
    
    # Handle system date fields
    for date_col in ["_updated_at", "_created_at"]:
        if date_col in df.columns:
            df[date_col] = df[date_col].apply(safe_date_convert)
    
    # Replace pandas NaN with None for SQL compatibility
    df = df.where(pd.notna(df), None)
    
    print(f"‚úÖ Data preparation complete. Ready for database insert.")
    return df

def chunked_insert(df, chunk_size=BATCH_SIZE):
    """Insert data in chunks with error handling"""
    print(f"üíæ Inserting {len(df)} records in chunks of {chunk_size}...")
    
    total_chunks = (len(df) + chunk_size - 1) // chunk_size
    successfully_inserted = 0
    
    for i, chunk_start in enumerate(range(0, len(df), chunk_size)):
        chunk_end = min(chunk_start + chunk_size, len(df))
        chunk = df.iloc[chunk_start:chunk_end]
        
        try:
            print(f"   üì¶ Chunk {i+1}/{total_chunks}: Inserting rows {chunk_start+1}-{chunk_end}...")
            
            db.insert_dataframe(
                chunk, 
                TABLE_NAME, 
                DATABASE_NAME,
                if_exists='append'
            )
            
            successfully_inserted += len(chunk)
            print(f"   ‚úÖ Chunk {i+1} inserted successfully ({len(chunk)} rows)")
            
        except Exception as e:
            print(f"   ‚ùå Chunk {i+1} failed: {e}")
            raise
    
    print(f"üéâ All chunks inserted! Total: {successfully_inserted} records")
    return successfully_inserted

async def main():
    """Main execution function with error handling"""
    start_time = time.time()
    
    try:
        print(f"üöÄ Starting ETL for Monday.com Board: {{ board_name }} (ID: {BOARD_ID})")
        print(f"üìã Target: {DATABASE_NAME}.dbo.{TABLE_NAME}")
        print(f"‚öôÔ∏è Configuration: Batch Size={BATCH_SIZE}, Max Workers={MAX_WORKERS}")
        print("=" * 80)
        
        # Step 1: Truncate existing data
        truncate_table()
        
        # Step 2: Fetch data from Monday.com
        items, board_name = fetch_board_data_with_pagination()
        
        if not items:
            print("‚ö†Ô∏è No items found in board. Exiting.")
            return
        
        # Step 3: Process items into DataFrame
        df = process_items(items)
        
        # Step 4: Prepare data for database
        df = prepare_for_database(df)
        
        # Step 5: Insert into database
        inserted_count = chunked_insert(df)
        
        # Step 6: Verification
        print("\nüîç Verifying insert...")
        verify_result = db.run_query(f"SELECT COUNT(*) as count FROM dbo.{TABLE_NAME}", DATABASE_NAME)
        final_count = verify_result.iloc[0]['count']
        
        elapsed_time = time.time() - start_time
        
        print("=" * 80)
        print(f"‚úÖ ETL COMPLETED SUCCESSFULLY!")
        print(f"üìä Records processed: {len(items):,}")
        print(f"üíæ Records inserted: {inserted_count:,}")
        print(f"üîç Final table count: {final_count:,}")
        print(f"‚è±Ô∏è Total time: {elapsed_time:.2f} seconds")
        print(f"üöÄ Performance: {len(items)/elapsed_time:.1f} records/second")
        
        if final_count != len(items):
            print(f"‚ö†Ô∏è WARNING: Count mismatch! Expected {len(items)}, got {final_count}")
        
    except Exception as e:
        elapsed_time = time.time() - start_time
        print("=" * 80)
        print(f"‚ùå ETL FAILED after {elapsed_time:.2f} seconds")
        print(f"üî• Error: {e}")
        print("üìß Please check logs and contact the data team.")
        raise

if __name__ == "__main__":
    asyncio.run(main())
